<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
    <style>
        body {
            background-color: white;
            padding: 15%;
            width: 70%;
            min-width: 70%;
            float: left;
            margin: auto;
            text-align: left;
            font-weight: 300;
            font-family: 'Open Sans', sans-serif;
            color: #121212;
        }

        .emphasis {
            text-decoration: underline;
        }


        h1, h2, h3, h4 {
            font-family: 'Source Sans Pro', sans-serif;
        }

        kbd {
            color: #121212;
        }
    </style>
    <title>CS 284A: Pathtracer 1</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8"/>
    <link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            }
        };
    </script>
    <script id="MathJax-script" async
            src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
    </script>

</head>


<body>

<h1 align="middle">CS 284A: Computer Graphics and Imaging, Spring 2023</h1>
<h1 align="middle">Project 3-1: Pathtracer</h1>
<h2 align="middle">IRINA HALLINAN & CECIL SYMES</h2>
<!-- Add Website URL -->
<h3 align="middle">Website URL: <a href="https://irina694.github.io/cs284-sp23-projects/proj3-1/">https://irina694.github.io/cs284-sp23-projects/proj3-1</a>
</h3>
<br><br>

<div>


    <h2 align="middle">Overview</h2>
    <p>
	<p>
		In this project, we implement physics-based rendering using path-tracing techniques. Specifically, we
		implemented 5 parts.
	</p>
	<ul>
		<li>In <span class="emphasis">Part 1</span> we generated a ray from the virtual camera and implemented
			primitives-ray intersections like sphere-ray and triangle-ray.
		</li>
		<li>In <span class="emphasis">Part 2</span> we implemented an optimization based on a Bounding Volume Hierarchy
			representation of objects to render our scenes more efficiently.
		</li>
		<li>In <span class="emphasis">Part 3</span> we calculated direct illumination using Monte Carlo Estimator, which
			happens when light goes from a light source directly into the camera or bounces off an object and then goes
			into the camera.
		</li>
		<li>In <span class="emphasis">Part 4</span> we implemented global illumination by recursively bouncing rays of
			light until they probabilistically stop with the Russian Roulette algorithm.
		</li>
		<li>In <span class="emphasis">Part 5</span> we implemented adaptive sampling to render images with less noise.
		</li>
	</ul>
	The details of each part are below.
	</p>
    </p>

    <br>

    <h2 align="middle">Part 1: Ray Generation and Scene Intersection (20 Points)</h2>
    <!-- Walk through the ray generation and primitive intersection parts of the rendering pipeline.
    Explain the triangle intersection algorithm you implemented in your own words.
    Show images with normal shading for a few small .dae files. -->

    <h3>
        Walk through the ray generation and primitive intersection parts of the rendering pipeline.
    </h3>
    <p>
        YOUR RESPONSE GOES HERE:
    </p>
	<p>

	</p>
    <br>

    <h3>
        Explain the triangle intersection algorithm you implemented in your own words.
    </h3>
    <p>
        YOUR RESPONSE GOES HERE
    </p>
    <br>

    <h3>
        Show images with normal shading for a few small .dae files.
    </h3>


    <h2 align="middle">Part 2: Bounding Volume Hierarchy (20 Points)</h2>
	<!-- Walk through 	your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
	Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
	Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis. -->

    <h3>
        Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting
        point.
    </h3>
    <p>
        In Part 2, we implemented Bounding Volume Hierarchy (BVH), to speed up how ray-object intersections are calculated in a scene. BVH is a recursive method to partition objects that alleviates inefficiency of a naive method of checking if a ray intersects every object. Our BVH implementation created a significant speed-up of rendering. Without BVH, the running complexity for calculating a ray-object intersection is <code>O(N)</code>. With BVH, the running complexity becomes <code>O(log_2(N))</code>. With BVH, we can render .dae files that are made of hundreds of thousands of triangles within seconds, which were infeasible to render without BVH.
    </p>

	<p>We constructed our BVH as follows:</p>

	<p>We construct the BVH recursively. At the start of the rendering, the lists of primitives are empty. We then construct the root node and point its <code>start</code> and <code>end</code> properties to the given empty lists of primitives. We then compute the bounding boxes for all primitives and count how many primitives there are. The figure below shows an example of the BVH, visualized on the <code>cow.dae</code> file. The left part of the BVH is highlighted in red.
	</p>

    <div align="middle">
        <table style="width:100%">
            <tr align="center">
                <td>
                    <img src="images/t2_bvh.png" align="middle" width="50%;"/>
                    <figcaption>The <code>cow.dae</code> in BVH Visualizer mode</figcaption>
                </td>
            </tr>
        </table>
    </div>

	<p>
	In the base case, if the number of primitives is less than maximum leaf size, we set the start and end pointers of the node to return.</p>
    <p></p>Otherwise, we get the median primitive by dividing the total primitive count by 2. Then, we sort all primitives. This is done by seeing which bounding box axis is the largest, then sorting it along this axis. We created custom functions to compare the centroids of bounding boxes (<code>sortByX</code>, <code>sortByY</code>, and <code>sortByZ</code>, which take the corresponding axis value for the input primitive's centroid, and returns true if the first item is smaller than the second item.</p>
    <p>The downside of this method is that we need to sort all the primitives every recursive call. Although this isn't very efficient, it is necessary because a child bounding box isn't guaranteed to have the same largest axis as its parent.</p>
    <p>Once the list is sorted, we recursively call the <code>construct_bvh</code> function on the left and right side, which become the left and right nodes of the root node. The two halves are created from the sorted list divided at the median primitive.</p>
    <p> Our debugging journey was the following:</p>
    <ul>
        <li>Took a while to realise that end() iterators point to the element AFTER the end, so no need to add + 1 to the start of the right child bbox func call</li>
        <li>At first, the idea was to take the average value of centroids, but it became clear that it is pretty common for almost all of the centroids in current bounding box to be the same along an axis, meaning that one child would be empty and there would be an infinite loop. Sorting by median means that it is guaranteed that child nodes are equal in terms of number of primitives.</li>
        <li>Used to create a new vector of primitive pointers on heap when at the base case, but realised that sorting in place makes it easier to handle and avoids potential memory leaks.</li>
    </ul>

    <h3>
        Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
    </h3>

    <p>Below are images that were generated by running the renderer with BVH using 8 threads. The maxplanck.dae contains over 50k primitives. The lucy.dae contains over 130k primitives. Both images are 800 x 600 pixels.</p>
    <div align="middle">
        <table style="width:100%">
            <tr align="center">
                <td>
                    <img src="images/t2_maxplanck.png" align="middle" width="75%;"/>
                    <figcaption>maxplanck.dae</figcaption>
                </td>
                <td>
                    <img src="images/t2_lucy.png" align="middle" width="75%;"/>
                    <figcaption>lucy.dae</figcaption>
                </td>
            </tr>
        </table>
    </div>
    <br>

	<h3>
	  Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis.
	</h3>
	<p>To compare the efficiency of using the BVH, we timed several images being rendered by the same number of rays, using the same number of threads. Starting with the simplest cube, which has only 12 primitives, there was no speedup. The time to sort the primitives in this small case offset the speedup in traversing the BVH tree. As expected, we see a significant speedup for more complex scenes. Some scenes are divided more evenly, like <code>maxplanck.dae</code> or <code>dragon.dae</code>. The exception where speedup was not as big is <code>building.dae</code>, a scene with a large number of primitives concentrated in one part of the scene.


    <table border="1px solid black;">
            <thead>
                <tr>
                    <td>
                        Filename
                    </td>
                    <td>
                        # of primitives
                    </td>
                    <td>
                        # of rays
                    </td>
                    <td>
                        # threads
                    </td>
                    <td>
                        Resolution (pixels)
                    </td>
                    <td>
                        With BVH (seconds)
                    </td>
                    <td>
                        Without BVH (seconds)
                    </td>
                    <td>
                        Speedup (times)
                    </td>
                </tr>
            </thead>
            <tbody>
            <tr>
                <td>
                    cube.dae
                </td>
                <td>
                    12
                </td>
                <td>
                    176,768
                </td>
                <td>
                    8
                </td>
                <td>
                    800x600
                </td>
                <td>
                    0.093072
                </td>
                <td>
                    0.091904
                </td>
                <td>
                    0.9875
                </td>
            </tr>
            <tr>
                <td>
                    bunny.dae
                </td>
                <td>
                    33,696
                </td>
                <td>
                    418,721
                </td>
                <td>
                    8
                </td>
                <td>
                    800x600
                </td>
                <td>
                    0.313027
                </td>
                <td>
                    32.3483
                </td>
                <td>
                    103.3403
                </td>
            </tr>
            <tr>
                <td>
                    building.dae
                </td>
                <td>
                    39,506
                </td>
                <td>
                    205,141
                </td>
                <td>
                    8
                </td>
                <td>
                    800x600
                </td>
                <td>
                    0.33361
                </td>
                <td>
                    9.64124
                </td>
                <td>
                    28.8997
                </td>
            </tr>
            <tr>
                <td>
                    maxplanck.dae
                </td>
                <td>
                    50,801
                </td>
                <td>
                    296,593
                </td>
                <td>
                    8
                </td>
                <td>
                    800x600
                </td>
                <td>
                    0.422581
                </td>
                <td>
                    64.7466
                </td>
                <td>
                    153.2170
                </td>
            </tr>
            <tr>
                <td>
                    dragon.dae
                </td>
                <td>
                    100,012
                </td>
                <td>
                    247,522
                </td>
                <td>
                    8
                </td>
                <td>
                    800x600
                </td>
                <td>
                    0.826029
                </td>
                <td>
                    108.905
                </td>
                <td>
                    131.8416
                </td>
            </tr>
            </tbody>
    </table>

	<br>

    <h2 align="middle">Part 3: Direct Illumination (20 Points)</h2>
    <!-- Walk through both implementations of the direct lighting function.
    Show some images rendered with both implementations of the direct lighting function.
    Focus on one particular scene with at least one area light and compare the noise levels in soft shadows when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, not uniform hemisphere sampling.
    Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis. -->

    <h3>
        Walk through both implementations of the direct lighting function.
    </h3>
	<p>FROM THE SPEC: Walk through both implementations of the direct lighting function.
		Show some images rendered with both implementations of the direct lighting function.
		Focus on one particular scene with at least one area light and compare the noise levels in soft shadows when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, not uniform hemisphere sampling.
		Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis.
	</p>
    <p>
        YOUR RESPONSE GOES HERE
    </p>

    <h3>
        Show some images rendered with both implementations of the direct lighting function.
    </h3>
    <!-- Example of including multiple figures -->
    <div align="middle">
        <table style="width:100%">
            <!-- Header -->
            <tr align="center">
                <th>
                    <b>Uniform Hemisphere Sampling</b>
                </th>
                <th>
                    <b>Light Sampling</b>
                </th>
            </tr>
            <br>
            <tr align="center">
                <td>
                    <img src="images/your_file.png" align="middle" width="400px"/>
                    <figcaption>example1.dae</figcaption>
                </td>
                <td>
                    <img src="images/your_file.png" align="middle" width="400px"/>
                    <figcaption>example1.dae</figcaption>
                </td>
            </tr>
            <br>
            <tr align="center">
                <td>
                    <img src="images/your_file.png" align="middle" width="400px"/>
                    <figcaption>example2.dae</figcaption>
                </td>
                <td>
                    <img src="images/your_file.png" align="middle" width="400px"/>
                    <figcaption>example2.dae</figcaption>
                </td>
            </tr>
            <br>
        </table>
    </div>
    <br>

    <h3>
        Focus on one particular scene with at least one area light and compare the noise levels in <b>soft
        shadows</b> when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the
        -s flag) using light sampling, <b>not</b> uniform hemisphere sampling.
    </h3>
    <!-- Example of including multiple figures -->
    <div align="middle">
        <table style="width:100%">
            <tr align="center">
                <td>
                    <img src="images/your_file.png" align="middle" width="200px"/>
                    <figcaption>1 Light Ray (example1.dae)</figcaption>
                </td>
                <td>
                    <img src="images/your_file.png" align="middle" width="200px"/>
                    <figcaption>4 Light Rays (example1.dae)</figcaption>
                </td>
            </tr>
            <tr align="center">
                <td>
                    <img src="images/your_file.png" align="middle" width="200px"/>
                    <figcaption>16 Light Rays (example1.dae)</figcaption>
                </td>
                <td>
                    <img src="images/your_file.png" align="middle" width="200px"/>
                    <figcaption>64 Light Rays (example1.dae)</figcaption>
                </td>
            </tr>
        </table>
    </div>
    <p>
        YOUR EXPLANATION GOES HERE
    </p>
    <br>

    <h3>
        Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis.
    </h3>
    <p>
        YOUR RESPONSE GOES HERE
    </p>
    <br>


    <h2 align="middle">Part 4: Global Illumination (20 Points)</h2>
   <!--
    Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
    For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
    Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
    You will probably want to use the instructional machines for the above renders in order to not burn up your own computer for hours. -->

    <h3>
        Walk through your implementation of the indirect lighting function.
    </h3>

    <!-- Walk through your implementation of the indirect lighting function.
   Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.-->
   <p>Global illumination consists of direct and indirect light. The indirect lightning comes from light bouncing off objects in the scene several times before reaching the camera. We implemented the global illumination by adding the zero-bounce (direct) and the at-least-one-bounce radiance (indirect). The zero-bounce radiance displays light directly from the light source. The at-least-one-bounce-radiance collects and displays light by adding radiance from rays bouncing at least once and bouncing multiple times, until a termination condition is reached. We used recursion to implement <code>at_least_one_bounce_radiance</code> and used the Russian Roulette as the unbiased probabilistic termination condition. The Russian Roulette ensures that all rays stop eventually, and the more bounces the rays have, the higher the probability of stopping after the next bounce. We start the probability of stopping as 0.3. The rays also were stopped if they reached their maximum depth, to avoid long termination times.</p>

   <p>Use 1024 samples per pixel.
       Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
       For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
       Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
       You will probably want to use the instructional machines for the above renders in order to not burn up your own computer for hours.</p>

   <p>
       YOUR RESPONSE GOES HERE
   </p>
   <br>

   <h3>
       Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
   </h3>
   <!-- Example of including multiple figures -->
    <div align="middle">
        <table style="width:100%">
            <tr align="center">
                <td>
                    <img src="images/your_file.png" align="middle" width="400px"/>
                    <figcaption>example1.dae</figcaption>
                </td>
                <td>
                    <img src="images/your_file.png" align="middle" width="400px"/>
                    <figcaption>example2.dae</figcaption>
                </td>
            </tr>
        </table>
    </div>
    <br>

    <h3>
        Pick one scene and compare rendered views first with only direct illumination, then only indirect
        illumination. Use 1024 samples per pixel. (You will have to edit
        PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
    </h3>
    <!-- Example of including multiple figures -->
    <div align="middle">
        <table style="width:100%">
            <tr align="center">
                <td>
                    <img src="images/your_file.png" align="middle" width="400px"/>
                    <figcaption>Only direct illumination (example1.dae)</figcaption>
                </td>
                <td>
                    <img src="images/your_file.png" align="middle" width="400px"/>
                    <figcaption>Only indirect illumination (example1.dae)</figcaption>
                </td>
            </tr>
        </table>
    </div>
    <br>
    <p>
        YOUR EXPLANATION GOES HERE
    </p>
    <br>

    <h3>
        For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use
        1024 samples per pixel.
    </h3>
    <!-- Example of including multiple figures -->
    <div align="middle">
        <table style="width:100%">
            <tr align="center">
                <td>
                    <img src="images/your_file.png" align="middle" width="400px"/>
                    <figcaption>max_ray_depth = 0 (CBbunny.dae)</figcaption>
                </td>
                <td>
                    <img src="images/your_file.png" align="middle" width="400px"/>
                    <figcaption>max_ray_depth = 1 (CBbunny.dae)</figcaption>
                </td>
            </tr>
            <tr align="center">
                <td>
                    <img src="images/your_file.png" align="middle" width="400px"/>
                    <figcaption>max_ray_depth = 2 (CBbunny.dae)</figcaption>
                </td>
                <td>
                    <img src="images/your_file.png" align="middle" width="400px"/>
                    <figcaption>max_ray_depth = 3 (CBbunny.dae)</figcaption>
                </td>
            </tr>
            <tr align="center">
                <td>
                    <img src="images/your_file.png" align="middle" width="400px"/>
                    <figcaption>max_ray_depth = 100 (CBbunny.dae)</figcaption>
                </td>
            </tr>
        </table>
    </div>
    <br>
    <p>
        YOUR EXPLANATION GOES HERE
    </p>
    <br>

    <h3>
        Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4,
        8, 16, 64, and 1024. Use 4 light rays.
    </h3>
    <!-- Example of including multiple figures -->
    <div align="middle">
        <table style="width:100%">
            <tr align="center">
                <td>
                    <img src="images/your_file.png" align="middle" width="400px"/>
                    <figcaption>1 sample per pixel (example1.dae)</figcaption>
                </td>
                <td>
                    <img src="images/your_file.png" align="middle" width="400px"/>
                    <figcaption>2 samples per pixel (example1.dae)</figcaption>
                </td>
            </tr>
            <tr align="center">
                <td>
                    <img src="images/your_file.png" align="middle" width="400px"/>
                    <figcaption>4 samples per pixel (example1.dae)</figcaption>
                </td>
                <td>
                    <img src="images/your_file.png" align="middle" width="400px"/>
                    <figcaption>8 samples per pixel (example1.dae)</figcaption>
                </td>
            </tr>
            <tr align="center">
                <td>
                    <img src="images/your_file.png" align="middle" width="400px"/>
                    <figcaption>16 samples per pixel (example1.dae)</figcaption>
                </td>
                <td>
                    <img src="images/your_file.png" align="middle" width="400px"/>
                    <figcaption>64 samples per pixel (example1.dae)</figcaption>
                </td>
            </tr>
            <tr align="center">
                <td>
                    <img src="images/your_file.png" align="middle" width="400px"/>
                    <figcaption>1024 samples per pixel (example1.dae)</figcaption>
                </td>
            </tr>
        </table>
    </div>
    <br>
    <p>
        YOUR EXPLANATION GOES HERE
    </p>
    <br>


    <h2 align="middle">Part 5: Adaptive Sampling (20 Points)</h2>
    <!-- Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
    Pick one scene and render it with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth. -->

    <h3>
        Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
    </h3>
	<p>FROM THE SPEC:</p>
	<p>Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
		Pick two scenes and render them with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth.</p>

    <p>
        YOUR RESPONSE GOES HERE
    </p>
    <br>

    <h3>
        Pick two scenes and render them with at least 2048 samples per pixel. Show a good sampling rate image with
        clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate
        image, which shows your how your adaptive sampling changes depending on which part of the image you are
        rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth.
    </h3>
    <!-- Example of including multiple figures -->
    <div align="middle">
        <table style="width:100%">
            <tr align="center">
                <td>
                    <img src="images/your_file.png" align="middle" width="400px"/>
                    <figcaption>Rendered image (example1.dae)</figcaption>
                </td>
                <td>
                    <img src="images/your_file.png" align="middle" width="400px"/>
                    <figcaption>Sample rate image (example1.dae)</figcaption>
                </td>
            </tr>
            <tr align="center">
                <td>
                    <img src="images/your_file.png" align="middle" width="400px"/>
                    <figcaption>Rendered image (example2.dae)</figcaption>
                </td>
                <td>
                    <img src="images/your_file.png" align="middle" width="400px"/>
                    <figcaption>Sample rate image (example2.dae)</figcaption>
                </td>
            </tr>
        </table>
    </div>
    <br>


	<p>At the end, if you worked with a partner, please write a short paragraph together for your final report that describes how you collaborated, how it went, and what you learned.</p>

	<h3 align="middle">Website URL: <a href="https://irina694.github.io/cs284-sp23-projects/proj3-1/">https://irina694.github.io/cs284-sp23-projects/proj3-1</a>
	</h3>


</div>
</body>
</html>